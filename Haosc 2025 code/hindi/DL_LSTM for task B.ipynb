{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "upset-insulin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation,Bidirectional,SpatialDropout1D\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ultimate-shame",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>task_2</th>\n",
       "      <th>task_3</th>\n",
       "      <th>task_4</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hindi_image_1817.jpg</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Vulgar</td>\n",
       "      <td>Abusive</td>\n",
       "      <td>Ba8@ DaNn G@rainiD IR T३ PDBB WRHE W PRD BCEN ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hindi_image_7.jpg</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Vulgar</td>\n",
       "      <td>Abusive</td>\n",
       "      <td>Nari nari mat kar pagle, Nari he nark ka dwar....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hindi_image_1.jpg</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Non Vulgar</td>\n",
       "      <td>Abusive</td>\n",
       "      <td>Kitni push ops maarsakte ho dafly? 5 aur agar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hindi_image_32.jpg</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Vulgar</td>\n",
       "      <td>Abusive</td>\n",
       "      <td>अब इसमें मेरी कहां गलती है बताओ.. तरबूज़ वाली क...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hindi_image_1714.jpg</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Non Vulgar</td>\n",
       "      <td>Abusive</td>\n",
       "      <td>\"KUDI MENU KEHNDl... 'MENU JUTI LA DE SONIYE.....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    _id    task_2      task_3   task_4  \\\n",
       "0  Hindi_image_1817.jpg   Neutral      Vulgar  Abusive   \n",
       "1     Hindi_image_7.jpg  Negative      Vulgar  Abusive   \n",
       "2     Hindi_image_1.jpg  Positive  Non Vulgar  Abusive   \n",
       "3    Hindi_image_32.jpg  Negative      Vulgar  Abusive   \n",
       "4  Hindi_image_1714.jpg  Negative  Non Vulgar  Abusive   \n",
       "\n",
       "                                          text_clean  \n",
       "0  Ba8@ DaNn G@rainiD IR T३ PDBB WRHE W PRD BCEN ...  \n",
       "1  Nari nari mat kar pagle, Nari he nark ka dwar....  \n",
       "2  Kitni push ops maarsakte ho dafly? 5 aur agar ...  \n",
       "3  अब इसमें मेरी कहां गलती है बताओ.. तरबूज़ वाली क...  \n",
       "4  \"KUDI MENU KEHNDl... 'MENU JUTI LA DE SONIYE.....  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../preprocess_data.csv')\n",
    "data.drop(['task_1','text'], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19fccf27-b582-4952-800c-a836de099d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>task_2</th>\n",
       "      <th>task_3</th>\n",
       "      <th>task_4</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hindi_image_410.jpg</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Vulgar</td>\n",
       "      <td>Non-abusive</td>\n",
       "      <td>Sign You are Bancho a] _ ~\"11|7 have best ffen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hindi_image_114.jpg</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Vulgar</td>\n",
       "      <td>Abusive</td>\n",
       "      <td>एक महिला घोडे़ के लिंग लिया| घोड़ा उत्साहित हो...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hindi_image_101.jpg</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Non Vulgar</td>\n",
       "      <td>Non-abusive</td>\n",
       "      <td>एक टीचर ने एक लड़के को पेपर में नक़ल करते पकड लि...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hindi_image_1747.jpg</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Vulgar</td>\n",
       "      <td>Abusive</td>\n",
       "      <td>show me Sckht Launda Kisslay Jha CTrollerlzabu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hindi_image_19.jpg</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Non Vulgar</td>\n",
       "      <td>Abusive</td>\n",
       "      <td>पति सुहागरात में पत्नी की निप्पल चूसते हुए बोल...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    _id    task_2      task_3       task_4  \\\n",
       "0   Hindi_image_410.jpg  Positive      Vulgar  Non-abusive   \n",
       "1   Hindi_image_114.jpg  Negative      Vulgar      Abusive   \n",
       "2   Hindi_image_101.jpg   Neutral  Non Vulgar  Non-abusive   \n",
       "3  Hindi_image_1747.jpg  Negative      Vulgar      Abusive   \n",
       "4    Hindi_image_19.jpg  Negative  Non Vulgar      Abusive   \n",
       "\n",
       "                                          text_clean  \n",
       "0  Sign You are Bancho a] _ ~\"11|7 have best ffen...  \n",
       "1  एक महिला घोडे़ के लिंग लिया| घोड़ा उत्साहित हो...  \n",
       "2  एक टीचर ने एक लड़के को पेपर में नक़ल करते पकड लि...  \n",
       "3  show me Sckht Launda Kisslay Jha CTrollerlzabu...  \n",
       "4  पति सुहागरात में पत्नी की निप्पल चूसते हुए बोल...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('../preprocess_test_data.csv')\n",
    "test_data.drop(['task_1','Unnamed: 0','text'], axis=1, inplace=True)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "piano-fairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = data['text_clean'].astype(str)\n",
    "tokenizer = Tokenizer(num_words = 1500,split=' ')\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "sequence = tokenizer.texts_to_sequences(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "147135a5-5dc2-4410-b72a-fcd5e990397c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = test_data['text_clean'].astype(str)\n",
    "test_sequence = tokenizer.texts_to_sequences(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "legitimate-program",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of unique words :  8859\n",
      "[[   0    0    0 ... 1173 1174  571]\n",
      " [   0    0    0 ...   19   15 1176]\n",
      " [   0    0    0 ...    4  773   17]\n",
      " ...\n",
      " [   0    0    0 ...   36  377   30]\n",
      " [   0    0    0 ...   27  122  333]\n",
      " [   0    0    0 ...  118  739   89]]\n"
     ]
    }
   ],
   "source": [
    "max_seq_len = 2500\n",
    "\n",
    "index_of_words = tokenizer.word_index\n",
    "print(\"No of unique words : \",len(index_of_words))\n",
    "\n",
    "X = pad_sequences(sequence , maxlen = max_seq_len )\n",
    "Y = data['task_2']\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1250385-72d8-4e5a-9722-25cf4eb7cd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...   46  963    9]\n",
      " [   0    0    0 ...   45   35   26]\n",
      " [   0    0    0 ...  545  310    2]\n",
      " ...\n",
      " [   0    0    0 ...   87  143  333]\n",
      " [   0    0    0 ...    0    0  318]\n",
      " [   0    0    0 ...    0    0 1297]]\n"
     ]
    }
   ],
   "source": [
    "test_X = pad_sequences(test_sequence , maxlen = max_seq_len )\n",
    "test_Y = test_data['task_2']\n",
    "\n",
    "print(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "talented-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 256\n",
    "vocabSize = len(index_of_words)\n",
    "lstm_out = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "institutional-luxembourg",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.15, random_state = 0)\n",
    "Y_true = Y_test\n",
    "Y_train = pd.get_dummies(Y_train).values\n",
    "Y_test = pd.get_dummies(Y_test).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62c4a8dd-931c-499f-9219-aec88a1ae04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_Y: [[False False  True]\n",
      " [ True False False]\n",
      " [False  True False]\n",
      " ...\n",
      " [False False  True]\n",
      " [False  True False]\n",
      " [False  True False]]\n"
     ]
    }
   ],
   "source": [
    "test_Y_true = test_Y\n",
    "test_Y = pd.get_dummies(test_Y).values\n",
    "print(\"test_Y:\",test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3efe01-b474-44bd-a4c4-0e3f082c54aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1c98b2e-4234-44f8-93c6-88202608cd76",
   "metadata": {},
   "source": [
    "# MODEL 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "reasonable-statistics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 2500, 256)         2267904   \n",
      "                                                                 \n",
      " spatial_dropout1d (Spatial  (None, 2500, 256)         0         \n",
      " Dropout1D)                                                      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                82176     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2350275 (8.97 MB)\n",
      "Trainable params: 2350275 (8.97 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabSize, embed_dim, input_length = 2500))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fuzzy-abuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(\"hasoc_a2.h5\", monitor='val_loss', verbose=1, save_best_only=True,\n",
    "save_weights_only=False, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "noble-accused",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018    Positive\n",
      "1020    Negative\n",
      "870     Positive\n",
      "184     Negative\n",
      "686     Negative\n",
      "          ...   \n",
      "55      Negative\n",
      "744     Positive\n",
      "785      Neutral\n",
      "946     Negative\n",
      "295     Positive\n",
      "Name: task_2, Length: 172, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(Y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "alone-launch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False  True]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [ True False False]\n",
      " [False  True False]\n",
      " [False  True False]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [False  True False]\n",
      " [ True False False]\n",
      " [ True False False]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [False  True False]\n",
      " [ True False False]\n",
      " [ True False False]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [False  True False]\n",
      " [False  True False]\n",
      " [ True False False]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [False  True False]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [False  True False]\n",
      " [False  True False]\n",
      " [ True False False]\n",
      " [False  True False]\n",
      " [False False  True]\n",
      " [False  True False]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [ True False False]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [False  True False]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [False  True False]\n",
      " [False False  True]\n",
      " [False  True False]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False  True False]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [False  True False]\n",
      " [False  True False]\n",
      " [ True False False]\n",
      " [False  True False]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False  True False]\n",
      " [ True False False]\n",
      " [False  True False]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [False  True False]\n",
      " [ True False False]\n",
      " [False  True False]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [ True False False]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [False  True False]\n",
      " [ True False False]\n",
      " [False  True False]\n",
      " [ True False False]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [False  True False]\n",
      " [ True False False]\n",
      " [ True False False]\n",
      " [False  True False]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [False  True False]\n",
      " [False False  True]\n",
      " [False  True False]\n",
      " [ True False False]\n",
      " [False  True False]\n",
      " [False  True False]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [False  True False]\n",
      " [ True False False]\n",
      " [False  True False]\n",
      " [False  True False]\n",
      " [False  True False]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [ True False False]\n",
      " [False  True False]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [ True False False]\n",
      " [False  True False]\n",
      " [False  True False]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False  True False]\n",
      " [ True False False]\n",
      " [ True False False]\n",
      " [False  True False]\n",
      " [False  True False]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False  True False]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [False  True False]\n",
      " [ True False False]\n",
      " [ True False False]\n",
      " [ True False False]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [False  True False]\n",
      " [False  True False]\n",
      " [False False  True]\n",
      " [False  True False]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [False  True False]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [False  True False]\n",
      " [ True False False]\n",
      " [False False  True]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_test)\n",
    "classes = ['Negative','Neutral','Positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "economic-separate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.6188 - accuracy: 0.4696\n",
      "Epoch 1: val_loss improved from inf to 0.62955, saving model to hasoc_a2.h5\n",
      "122/122 [==============================] - 235s 2s/step - loss: 0.6188 - accuracy: 0.4696 - val_loss: 0.6295 - val_accuracy: 0.4012\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\8888\\Anaconda3\\envs\\pythonProject11\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - ETA: 0s - loss: 0.5648 - accuracy: 0.5635\n",
      "Epoch 2: val_loss improved from 0.62955 to 0.60418, saving model to hasoc_a2.h5\n",
      "122/122 [==============================] - 249s 2s/step - loss: 0.5648 - accuracy: 0.5635 - val_loss: 0.6042 - val_accuracy: 0.4767\n",
      "Epoch 3/10\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.4347 - accuracy: 0.7069\n",
      "Epoch 3: val_loss did not improve from 0.60418\n",
      "122/122 [==============================] - 249s 2s/step - loss: 0.4347 - accuracy: 0.7069 - val_loss: 0.7060 - val_accuracy: 0.4186\n",
      "Epoch 4/10\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.2855 - accuracy: 0.8215\n",
      "Epoch 4: val_loss did not improve from 0.60418\n",
      "122/122 [==============================] - 246s 2s/step - loss: 0.2855 - accuracy: 0.8215 - val_loss: 0.8076 - val_accuracy: 0.4651\n",
      "Epoch 5/10\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.1991 - accuracy: 0.8906\n",
      "Epoch 5: val_loss did not improve from 0.60418\n",
      "122/122 [==============================] - 246s 2s/step - loss: 0.1991 - accuracy: 0.8906 - val_loss: 1.0807 - val_accuracy: 0.4302\n",
      "Epoch 6/10\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.1415 - accuracy: 0.9133\n",
      "Epoch 6: val_loss did not improve from 0.60418\n",
      "122/122 [==============================] - 247s 2s/step - loss: 0.1415 - accuracy: 0.9133 - val_loss: 1.1603 - val_accuracy: 0.4709\n",
      "Epoch 7/10\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.1013 - accuracy: 0.9401\n",
      "Epoch 7: val_loss did not improve from 0.60418\n",
      "122/122 [==============================] - 246s 2s/step - loss: 0.1013 - accuracy: 0.9401 - val_loss: 1.3860 - val_accuracy: 0.4360\n",
      "Epoch 8/10\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.0961 - accuracy: 0.9412\n",
      "Epoch 8: val_loss did not improve from 0.60418\n",
      "122/122 [==============================] - 247s 2s/step - loss: 0.0961 - accuracy: 0.9412 - val_loss: 1.2587 - val_accuracy: 0.4477\n",
      "Epoch 9/10\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.0870 - accuracy: 0.9474\n",
      "Epoch 9: val_loss did not improve from 0.60418\n",
      "122/122 [==============================] - 264s 2s/step - loss: 0.0870 - accuracy: 0.9474 - val_loss: 1.4625 - val_accuracy: 0.4419\n",
      "Epoch 10/10\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.0686 - accuracy: 0.9567\n",
      "Epoch 10: val_loss did not improve from 0.60418\n",
      "122/122 [==============================] - 338s 3s/step - loss: 0.0686 - accuracy: 0.9567 - val_loss: 1.5980 - val_accuracy: 0.4419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e72c72c250>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size = 8, epochs = 10 , validation_data = (X_test, Y_test), callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e15175f-cde4-40af-b649-9ce830a061a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 4s 620ms/step - loss: 0.6042 - accuracy: 0.4767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6041780710220337, 0.4767441749572754]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('hasoc_a2.h5')\n",
    "model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "frozen-battlefield",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 17s 665ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "guided-damages",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03771292 0.07741701 0.88487005]\n",
      " [0.19440939 0.18823677 0.6173538 ]\n",
      " [0.61268383 0.146672   0.24064414]\n",
      " ...\n",
      " [0.37182772 0.15705739 0.47111484]\n",
      " [0.65076727 0.16120294 0.1880298 ]\n",
      " [0.7870871  0.11707791 0.09583499]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Y_pred:\",Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "handy-times",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 0, 2, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 2, 2, 2, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 2, 0, 0, 0, 2, 2, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 2, 2, 0, 0, 2, 2, 0, 0, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 2, 2, 0, 0, 2, 2, 2, 2, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 2, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 2, 0, 0]\n",
      "[[False False  True]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " ...\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [ True False False]]\n"
     ]
    }
   ],
   "source": [
    "pred_class = []\n",
    "for i in Y_pred:\n",
    "    pred_class.append(np.argmax(i))\n",
    "print(pred_class)\n",
    "\n",
    "pred_class_condition = pd.get_dummies(pred_class).values\n",
    "print(pred_class_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "blind-pricing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.76      0.18        76\n",
      "           1       1.00      0.00      0.01       648\n",
      "           2       0.09      0.42      0.15        45\n",
      "\n",
      "   micro avg       0.10      0.10      0.10       769\n",
      "   macro avg       0.40      0.40      0.11       769\n",
      "weighted avg       0.86      0.10      0.03       769\n",
      " samples avg       0.10      0.10      0.10       769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_Y, pred_class_condition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "tough-houston",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_actual = []\n",
    "for i in pred_class:\n",
    "    if i == 0:\n",
    "        pred_actual.append('Negative')\n",
    "    elif i == 1 :\n",
    "        pred_actual.append('Neutral')\n",
    "    else:\n",
    "        pred_actual.append('Positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf9dec04-7c69-4f9e-8a2d-58348087ecd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hindi_image_410.jpg</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hindi_image_114.jpg</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hindi_image_101.jpg</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hindi_image_1747.jpg</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hindi_image_19.jpg</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    _id     label\n",
       "0   Hindi_image_410.jpg  Positive\n",
       "1   Hindi_image_114.jpg  Positive\n",
       "2   Hindi_image_101.jpg  Negative\n",
       "3  Hindi_image_1747.jpg  Positive\n",
       "4    Hindi_image_19.jpg  Positive"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = test_data[[\"_id\"]]\n",
    "test_data[\"label\"] = pred_actual\n",
    "test_data.to_csv('dl_lstm_a2.csv',index=False)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69321cc-17d8-4c3e-bd8e-6bb0214bdbc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34b3e2b4-fca6-4d0f-9a88-28a07970c16e",
   "metadata": {},
   "source": [
    "# MODEL 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7396d46f-f8d1-436f-8f34-abc4daee4b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 2500, 256)         2267904   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2500, 256)         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                82176     \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 64)                256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2350531 (8.97 MB)\n",
      "Trainable params: 2350403 (8.97 MB)\n",
      "Non-trainable params: 128 (512.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Embedding层，增加防止过拟合的Dropout\n",
    "model.add(Embedding(input_dim=vocabSize, output_dim=embed_dim, input_length=2500))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# LSTM层，增加recurrent_dropout 和 output dropout\n",
    "model.add(LSTM(units=lstm_out, dropout=0.3, recurrent_dropout=0.3, return_sequences=False))\n",
    "\n",
    "# Batch Normalization增强泛化\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 全连接层，Softmax输出3分类，建议用categorical_crossentropy\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# 编译\n",
    "optimizer = Adam(learning_rate=0.001)  # 学习率也可调整\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5046ee41-c3eb-40ce-bc9d-e0343e00a36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(\"hasoc_b2.h5\", monitor='val_loss', verbose=1, save_best_only=True,\n",
    "save_weights_only=False, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c276c8e-f25c-4879-8c3e-7f0e61851f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.1616 - accuracy: 0.3891\n",
      "Epoch 1: val_loss improved from inf to 1.09600, saving model to hasoc_b2.h5\n",
      "122/122 [==============================] - 333s 3s/step - loss: 1.1616 - accuracy: 0.3891 - val_loss: 1.0960 - val_accuracy: 0.3837\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\8888\\Anaconda3\\envs\\pythonProject11\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - ETA: 0s - loss: 0.8200 - accuracy: 0.6460\n",
      "Epoch 2: val_loss improved from 1.09600 to 1.08187, saving model to hasoc_b2.h5\n",
      "122/122 [==============================] - 335s 3s/step - loss: 0.8200 - accuracy: 0.6460 - val_loss: 1.0819 - val_accuracy: 0.3837\n",
      "Epoch 3/10\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.6100 - accuracy: 0.7317\n",
      "Epoch 3: val_loss improved from 1.08187 to 1.06746, saving model to hasoc_b2.h5\n",
      "122/122 [==============================] - 338s 3s/step - loss: 0.6100 - accuracy: 0.7317 - val_loss: 1.0675 - val_accuracy: 0.4419\n",
      "Epoch 4/10\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.4266 - accuracy: 0.8318\n",
      "Epoch 4: val_loss did not improve from 1.06746\n",
      "122/122 [==============================] - 337s 3s/step - loss: 0.4266 - accuracy: 0.8318 - val_loss: 1.2577 - val_accuracy: 0.4419\n",
      "Epoch 5/10\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.4071 - accuracy: 0.8452\n",
      "Epoch 5: val_loss did not improve from 1.06746\n",
      "122/122 [==============================] - 340s 3s/step - loss: 0.4071 - accuracy: 0.8452 - val_loss: 1.5023 - val_accuracy: 0.4419\n",
      "Epoch 6/10\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.3706 - accuracy: 0.8524\n",
      "Epoch 6: val_loss did not improve from 1.06746\n",
      "122/122 [==============================] - 334s 3s/step - loss: 0.3706 - accuracy: 0.8524 - val_loss: 1.6529 - val_accuracy: 0.4302\n",
      "Epoch 7/10\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.3356 - accuracy: 0.8627\n",
      "Epoch 7: val_loss did not improve from 1.06746\n",
      "122/122 [==============================] - 338s 3s/step - loss: 0.3356 - accuracy: 0.8627 - val_loss: 2.0850 - val_accuracy: 0.4302\n",
      "Epoch 8/10\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.3183 - accuracy: 0.8720\n",
      "Epoch 8: val_loss did not improve from 1.06746\n",
      "122/122 [==============================] - 338s 3s/step - loss: 0.3183 - accuracy: 0.8720 - val_loss: 2.1050 - val_accuracy: 0.4302\n",
      "Epoch 9/10\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.3206 - accuracy: 0.8782\n",
      "Epoch 9: val_loss did not improve from 1.06746\n",
      "122/122 [==============================] - 334s 3s/step - loss: 0.3206 - accuracy: 0.8782 - val_loss: 2.1498 - val_accuracy: 0.4302\n",
      "Epoch 10/10\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.2862 - accuracy: 0.8989\n",
      "Epoch 10: val_loss did not improve from 1.06746\n",
      "122/122 [==============================] - 340s 3s/step - loss: 0.2862 - accuracy: 0.8989 - val_loss: 2.1212 - val_accuracy: 0.4244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1aca04ecb50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size = 8, epochs = 10, validation_data = (X_test, Y_test), callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2397e27a-59aa-475d-9395-2318f6e30c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 4s 649ms/step - loss: 1.0675 - accuracy: 0.4419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.067458987236023, 0.44186046719551086]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('hasoc_b2.h5')\n",
    "model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2001896f-08d6-487d-8163-03bb467cebd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 17s 682ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84b4dafd-15c0-4753-88ab-69407633dced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 2, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 2, 2, 1, 0, 1, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 2, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 1, 2, 2, 2, 0, 2, 0, 2, 1, 2, 0, 0, 2, 0, 1, 2, 0, 1, 0, 0, 2, 0, 0, 2, 0, 2, 0, 1, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 2, 2, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 2, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 2, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 1, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 1, 0, 0, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 1, 2, 0, 0, 0, 0, 2, 2, 2, 2, 0, 0, 2, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2, 2, 2, 0, 0, 1, 0, 1, 0, 2, 0, 2, 1, 2, 2, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 2, 0, 1, 0, 0, 1, 0, 0, 0, 2, 2, 2, 1, 1, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 2, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 2, 1, 2, 2, 0, 0, 2, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 2, 2, 2, 0, 2, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 1, 1, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "[[False False  True]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " ...\n",
      " [ True False False]\n",
      " [ True False False]\n",
      " [ True False False]]\n"
     ]
    }
   ],
   "source": [
    "pred_class = []\n",
    "for i in Y_pred:\n",
    "    pred_class.append(np.argmax(i))\n",
    "print(pred_class)\n",
    "\n",
    "pred_class_condition = pd.get_dummies(pred_class).values\n",
    "print(pred_class_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d872454-1bd7-45ce-a533-311c380e453b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.76      0.18        76\n",
      "           1       0.88      0.12      0.21       648\n",
      "           2       0.05      0.13      0.07        45\n",
      "\n",
      "   micro avg       0.19      0.19      0.19       769\n",
      "   macro avg       0.34      0.34      0.16       769\n",
      "weighted avg       0.75      0.19      0.20       769\n",
      " samples avg       0.19      0.19      0.19       769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_Y, pred_class_condition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51d3ebb1-64ea-4861-afca-bd0872c6652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_actual = []\n",
    "for i in pred_class:\n",
    "    if i == 0:\n",
    "        pred_actual.append('Negative')\n",
    "    elif i == 1 :\n",
    "        pred_actual.append('Neutral')\n",
    "    else:\n",
    "        pred_actual.append('Positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80ee0d32-4d11-4182-8b9f-e199ffb6bc58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hindi_image_410.jpg</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hindi_image_114.jpg</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hindi_image_101.jpg</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hindi_image_1747.jpg</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hindi_image_19.jpg</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    _id     label\n",
       "0   Hindi_image_410.jpg  Positive\n",
       "1   Hindi_image_114.jpg  Positive\n",
       "2   Hindi_image_101.jpg  Negative\n",
       "3  Hindi_image_1747.jpg  Negative\n",
       "4    Hindi_image_19.jpg  Positive"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = test_data[[\"_id\"]]\n",
    "test_data[\"label\"] = pred_actual\n",
    "test_data.to_csv('dl_lstm_b2.csv',index=False)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973c2566-c1ee-4391-ade7-15dd8fd7c9c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d68de15-2a17-4c7b-a0b7-1a252f59cd01",
   "metadata": {},
   "source": [
    "# MODEL 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6957a30e-398d-496a-bb22-21a3ce35a999",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(\n",
    "    \"hasoc_c2.h5\",\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False, \n",
    "    mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc13c015-5e87-4527-81d3-3fd91c262327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0951 - accuracy: 0.3633\n",
      "Epoch 1: val_loss improved from inf to 1.07616, saving model to hasoc_c2.h5\n",
      "122/122 [==============================] - 332s 3s/step - loss: 1.0951 - accuracy: 0.3633 - val_loss: 1.0762 - val_accuracy: 0.4593\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\8888\\Anaconda3\\envs\\pythonProject11\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - ETA: 0s - loss: 0.9417 - accuracy: 0.6058\n",
      "Epoch 2: val_loss did not improve from 1.07616\n",
      "122/122 [==============================] - 332s 3s/step - loss: 0.9417 - accuracy: 0.6058 - val_loss: 1.0903 - val_accuracy: 0.4826\n",
      "Epoch 3/10\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.6107 - accuracy: 0.7441\n",
      "Epoch 3: val_loss did not improve from 1.07616\n",
      "122/122 [==============================] - 332s 3s/step - loss: 0.6107 - accuracy: 0.7441 - val_loss: 1.2450 - val_accuracy: 0.4302\n",
      "Epoch 4/10\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.3498 - accuracy: 0.8535\n",
      "Epoch 4: val_loss did not improve from 1.07616\n",
      "122/122 [==============================] - 331s 3s/step - loss: 0.3498 - accuracy: 0.8535 - val_loss: 1.6500 - val_accuracy: 0.4884\n",
      "Epoch 5/10\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.2279 - accuracy: 0.9082\n",
      "Epoch 5: val_loss did not improve from 1.07616\n",
      "122/122 [==============================] - 330s 3s/step - loss: 0.2279 - accuracy: 0.9082 - val_loss: 1.8564 - val_accuracy: 0.4302\n",
      "Epoch 6/10\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.1660 - accuracy: 0.9319\n",
      "Epoch 6: val_loss did not improve from 1.07616\n",
      "122/122 [==============================] - 331s 3s/step - loss: 0.1660 - accuracy: 0.9319 - val_loss: 2.2772 - val_accuracy: 0.4419\n",
      "Epoch 7/10\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.1244 - accuracy: 0.9474\n",
      "Epoch 7: val_loss did not improve from 1.07616\n",
      "122/122 [==============================] - 328s 3s/step - loss: 0.1244 - accuracy: 0.9474 - val_loss: 2.4551 - val_accuracy: 0.4360\n",
      "Epoch 8/10\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.1103 - accuracy: 0.9463\n",
      "Epoch 8: val_loss did not improve from 1.07616\n",
      "122/122 [==============================] - 333s 3s/step - loss: 0.1103 - accuracy: 0.9463 - val_loss: 2.6664 - val_accuracy: 0.4593\n",
      "Epoch 9/10\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.1418 - accuracy: 0.9401\n",
      "Epoch 9: val_loss did not improve from 1.07616\n",
      "122/122 [==============================] - 324s 3s/step - loss: 0.1418 - accuracy: 0.9401 - val_loss: 2.4368 - val_accuracy: 0.4302\n",
      "Epoch 10/10\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.1120 - accuracy: 0.9463\n",
      "Epoch 10: val_loss did not improve from 1.07616\n",
      "122/122 [==============================] - 323s 3s/step - loss: 0.1120 - accuracy: 0.9463 - val_loss: 2.7736 - val_accuracy: 0.4477\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1b3060772e0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabSize, embed_dim, input_length=2500))\n",
    "model.add(LSTM(lstm_out, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "# 假设Y_train已独热编码\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.array([0, 1, 2]), y=np.argmax(Y_train, axis=1))\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=10, batch_size=8, class_weight=class_weight_dict, validation_data=(X_test,Y_test), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30f66f35-5919-494b-84ba-1f2a5992a3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 4s 651ms/step - loss: 1.0762 - accuracy: 0.4593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0761574506759644, 0.4593023359775543]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('hasoc_c2.h5')\n",
    "model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01925065-5cb5-4637-9cc9-45bed02dc465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 17s 668ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6fcff70-ff4c-4f60-9ccd-318691c1bce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 2, 2, 2, 0, 0, 0, 2, 0, 0, 1, 0, 0, 1, 2, 0, 2, 2, 2, 2, 2, 0, 1, 2, 2, 0, 0, 0, 0, 2, 2, 2, 0, 0, 2, 0, 1, 0, 0, 1, 0, 2, 1, 0, 0, 0, 1, 0, 0, 0, 0, 2, 2, 2, 2, 0, 0, 2, 0, 2, 0, 0, 2, 2, 0, 2, 0, 0, 1, 0, 2, 0, 2, 1, 0, 0, 2, 2, 1, 0, 1, 0, 2, 2, 2, 2, 0, 2, 0, 2, 0, 0, 0, 0, 2, 2, 1, 0, 0, 2, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 2, 1, 1, 2, 2, 2, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 0, 1, 0, 1, 0, 2, 0, 0, 2, 0, 2, 2, 1, 0, 2, 1, 2, 2, 0, 0, 2, 2, 0, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 0, 2, 0, 0, 1, 2, 2, 1, 0, 2, 2, 2, 2, 2, 1, 1, 0, 2, 2, 2, 2, 0, 2, 2, 1, 2, 2, 2, 0, 0, 0, 1, 0, 2, 0, 1, 0, 0, 2, 0, 0, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 2, 1, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 1, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 2, 1, 0, 0, 1, 0, 2, 1, 0, 0, 2, 2, 1, 0, 0, 0, 1, 2, 1, 1, 1, 1, 2, 2, 0, 2, 1, 1, 0, 2, 1, 0, 2, 0, 2, 0, 0, 1, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 1, 2, 2, 1, 0, 2, 2, 1, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 2, 1, 0, 2, 2, 2, 1, 1, 0, 0, 0, 1, 0, 2, 2, 2, 0, 0, 2, 2, 0, 1, 2, 2, 2, 0, 0, 2, 1, 0, 0, 1, 2, 2, 2, 0, 0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 1, 2, 2, 1, 0, 2, 1, 0, 2, 2, 1, 0, 0, 0, 0, 0, 1, 2, 1, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 1, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 1, 2, 2, 2, 0, 2, 0, 2, 1, 1, 0, 0, 0, 0, 1, 2, 0, 2, 1, 0, 2, 2, 2, 0, 0, 1, 0, 0, 1, 0, 2, 2, 0, 0, 0, 2, 2, 0, 2, 0, 1, 2, 2, 0, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 1, 2, 2, 2, 1, 0, 2, 2, 2, 1, 2, 0, 2, 1, 2, 1, 1, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 1, 2, 2, 0, 2, 1, 2, 2, 1, 2, 1, 2, 0, 2, 1, 2, 2, 0, 0, 2, 1, 0, 0, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 0, 0, 1, 2, 0, 2, 2, 2, 1, 0, 0, 2, 2, 2, 2, 0, 2, 2, 1, 2, 2, 2, 2, 2, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 1, 2, 0, 2, 0, 0, 1, 2, 2, 2, 2, 1, 1, 2, 0, 1, 2, 1, 2, 1, 1, 1, 2, 2, 2, 0, 1, 2, 2, 2, 2, 1, 2, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 1, 2, 1, 1, 2, 2, 0, 1, 2, 1, 0, 2, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 1, 2, 2, 2, 1, 0, 1, 2, 2, 2, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 1, 2, 1, 0, 0, 2, 1, 0, 2, 2, 2, 2, 1, 1, 0, 0, 2, 1, 2, 0, 2, 0, 2, 2, 2, 2, 0, 1, 2, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 1, 2, 2, 0, 0, 0, 2, 0, 0, 2, 2, 0, 1, 2, 0, 0]\n",
      "[[False False  True]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " ...\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [ True False False]]\n"
     ]
    }
   ],
   "source": [
    "pred_class = []\n",
    "for i in Y_pred:\n",
    "    pred_class.append(np.argmax(i))\n",
    "print(pred_class)\n",
    "\n",
    "pred_class_condition = pd.get_dummies(pred_class).values\n",
    "print(pred_class_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0bdcbba-6380-48cc-97a4-dba5a2ffce75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.36      0.16        76\n",
      "           1       0.93      0.17      0.29       648\n",
      "           2       0.08      0.64      0.14        45\n",
      "\n",
      "   micro avg       0.22      0.22      0.22       769\n",
      "   macro avg       0.37      0.39      0.19       769\n",
      "weighted avg       0.80      0.22      0.27       769\n",
      " samples avg       0.22      0.22      0.22       769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_Y, pred_class_condition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9408d0c1-a632-4069-97f4-dea31ebd0d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_actual = []\n",
    "for i in pred_class:\n",
    "    if i == 0:\n",
    "        pred_actual.append('Negative')\n",
    "    elif i == 1 :\n",
    "        pred_actual.append('Neutral')\n",
    "    else:\n",
    "        pred_actual.append('Positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30625d02-1c51-4169-969a-1dc4d0e5a22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hindi_image_410.jpg</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hindi_image_114.jpg</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hindi_image_101.jpg</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hindi_image_1747.jpg</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hindi_image_19.jpg</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    _id     label\n",
       "0   Hindi_image_410.jpg  Positive\n",
       "1   Hindi_image_114.jpg  Positive\n",
       "2   Hindi_image_101.jpg  Positive\n",
       "3  Hindi_image_1747.jpg  Positive\n",
       "4    Hindi_image_19.jpg  Positive"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = test_data[[\"_id\"]]\n",
    "test_data[\"label\"] = pred_actual\n",
    "test_data.to_csv('dl_lstm_c2.csv',index=False)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8f1c0d-a1cc-48da-8201-286bf0ff8a87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
