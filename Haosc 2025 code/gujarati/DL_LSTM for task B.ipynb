{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "upset-insulin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation,Bidirectional,SpatialDropout1D\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ultimate-shame",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>task_2</th>\n",
       "      <th>task_3</th>\n",
       "      <th>task_4</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gujarati_image_1618.jpg</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Vulgar</td>\n",
       "      <td>Abusive</td>\n",
       "      <td>છોકર). ટીચર તમાર તાજમહેલ\\r\\n\\r\\nદેખ/ય છે.\\r\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gujarati_image_31.jpg</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Vulgar</td>\n",
       "      <td>Abusive</td>\n",
       "      <td>છોકરો : ના.\\r\\n છોકરી : કેમ?\\r\\n \\r\\n છોકરી : ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gujarati_image_1144.jpg</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Vulgar</td>\n",
       "      <td>Abusive</td>\n",
       "      <td>છોકરીઓ ગમે તેટલી\\r\\n ચાલક હોય,\\r\\n \\r\\n પણ છોક...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gujarati_image_1184.jpg</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Vulgar</td>\n",
       "      <td>Abusive</td>\n",
       "      <td>દોસ્તી કરો,પ્રેમ કરો, વફા કરો...\\r\\n અને બહુ મ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gujarati_image_1643.jpg</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Vulgar</td>\n",
       "      <td>Abusive</td>\n",
       "      <td>છોકરીઓ ગમે તેટલી\\r\\nચાલક હોય,\\r\\n\\r\\nપણ છોકરા ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       _id    task_2  task_3   task_4  \\\n",
       "0  Gujarati_image_1618.jpg  Positive  Vulgar  Abusive   \n",
       "1    Gujarati_image_31.jpg  Positive  Vulgar  Abusive   \n",
       "2  Gujarati_image_1144.jpg  Negative  Vulgar  Abusive   \n",
       "3  Gujarati_image_1184.jpg  Negative  Vulgar  Abusive   \n",
       "4  Gujarati_image_1643.jpg   Neutral  Vulgar  Abusive   \n",
       "\n",
       "                                          text_clean  \n",
       "0  છોકર). ટીચર તમાર તાજમહેલ\\r\\n\\r\\nદેખ/ય છે.\\r\\n\\...  \n",
       "1  છોકરો : ના.\\r\\n છોકરી : કેમ?\\r\\n \\r\\n છોકરી : ...  \n",
       "2  છોકરીઓ ગમે તેટલી\\r\\n ચાલક હોય,\\r\\n \\r\\n પણ છોક...  \n",
       "3  દોસ્તી કરો,પ્રેમ કરો, વફા કરો...\\r\\n અને બહુ મ...  \n",
       "4  છોકરીઓ ગમે તેટલી\\r\\nચાલક હોય,\\r\\n\\r\\nપણ છોકરા ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../preprocess_data.csv')\n",
    "data.drop(['task_1','text'], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcf3952e-0a3c-4b1a-8147-2b0bc755cef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>task_2</th>\n",
       "      <th>task_3</th>\n",
       "      <th>task_4</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gujarati_image_1225.jpg</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Non Vulgar</td>\n",
       "      <td>Non-abusive</td>\n",
       "      <td>॥વિંદેશીગામડિયો\\r\\n અ |</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gujarati_image_1583.jpg</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Vulgar</td>\n",
       "      <td>Abusive</td>\n",
       "      <td>ટીચર : સૌથી વધારે દુખાવો ક્યારે\\r\\nથાય?\\r\\nછોક...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gujarati_image_1502.jpg</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Vulgar</td>\n",
       "      <td>Abusive</td>\n",
       "      <td>પતિ: તુંમને જરાય પ્રેમ\\r\\nનથી કરતી...\\r\\n\\r\\nપ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gujarati_image_1487.jpg</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Vulgar</td>\n",
       "      <td>Abusive</td>\n",
       "      <td>આખા ગોમ ના લોડા\\r\\nભોસ મા ભરી ને બેઠી\\r\\nહોય અ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gujarati_image_1497.jpg</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Vulgar</td>\n",
       "      <td>Abusive</td>\n",
       "      <td>મિનરલ વોટર સિવાય ક્યારેય\\r\\nબીજું\\r\\nપાણી નો પ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       _id    task_2      task_3       task_4  \\\n",
       "0  Gujarati_image_1225.jpg   Neutral  Non Vulgar  Non-abusive   \n",
       "1  Gujarati_image_1583.jpg  Negative      Vulgar      Abusive   \n",
       "2  Gujarati_image_1502.jpg  Positive      Vulgar      Abusive   \n",
       "3  Gujarati_image_1487.jpg  Negative      Vulgar      Abusive   \n",
       "4  Gujarati_image_1497.jpg  Negative      Vulgar      Abusive   \n",
       "\n",
       "                                          text_clean  \n",
       "0                            ॥વિંદેશીગામડિયો\\r\\n અ |  \n",
       "1  ટીચર : સૌથી વધારે દુખાવો ક્યારે\\r\\nથાય?\\r\\nછોક...  \n",
       "2  પતિ: તુંમને જરાય પ્રેમ\\r\\nનથી કરતી...\\r\\n\\r\\nપ...  \n",
       "3  આખા ગોમ ના લોડા\\r\\nભોસ મા ભરી ને બેઠી\\r\\nહોય અ...  \n",
       "4  મિનરલ વોટર સિવાય ક્યારેય\\r\\nબીજું\\r\\nપાણી નો પ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('../preprocess_test_data.csv')\n",
    "test_data.drop(['task_1','Unnamed: 0','text'], axis=1, inplace=True)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "piano-fairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = data['text_clean'].astype(str)\n",
    "tokenizer = Tokenizer(num_words = 1500,split=' ')\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "sequence = tokenizer.texts_to_sequences(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "932ecd4b-1656-4459-b33a-b2fac07b7005",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = test_data['text_clean'].astype(str)\n",
    "test_sequence = tokenizer.texts_to_sequences(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "legitimate-program",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of unique words :  7000\n",
      "[[   0    0    0 ...  536  134    1]\n",
      " [   0    0    0 ...  246 1062  318]\n",
      " [   0    0    0 ... 1067 1068  174]\n",
      " ...\n",
      " [   0    0    0 ...    0    0    5]\n",
      " [   0    0    0 ...    0    0    5]\n",
      " [   0    0    0 ...    1   17  433]]\n"
     ]
    }
   ],
   "source": [
    "max_seq_len = 2500\n",
    "\n",
    "index_of_words = tokenizer.word_index\n",
    "print(\"No of unique words : \",len(index_of_words))\n",
    "\n",
    "X = pad_sequences(sequence , maxlen = max_seq_len )\n",
    "Y = data['task_2']\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32e32105-29f7-47a2-8922-36d26df53ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0 ...   0   0 648]\n",
      " [  0   0   0 ... 206 394   1]\n",
      " [  0   0   0 ...   2   1   1]\n",
      " ...\n",
      " [  0   0   0 ...   1   1 324]\n",
      " [  0   0   0 ...  40   2   1]\n",
      " [  0   0   0 ...   0   0   5]]\n"
     ]
    }
   ],
   "source": [
    "test_X = pad_sequences(test_sequence , maxlen = max_seq_len )\n",
    "test_Y = test_data['task_2']\n",
    "\n",
    "print(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "talented-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 256\n",
    "vocabSize = len(index_of_words)\n",
    "lstm_out = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "institutional-luxembourg",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.15, random_state = 0)\n",
    "Y_true = Y_test\n",
    "Y_train = pd.get_dummies(Y_train).values\n",
    "Y_test = pd.get_dummies(Y_test).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f6324b3-a5bc-4757-a925-a390645c3960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_Y: [[False  True False]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " ...\n",
      " [False  True False]\n",
      " [False  True False]\n",
      " [False  True False]]\n"
     ]
    }
   ],
   "source": [
    "test_Y_true = test_Y\n",
    "test_Y = pd.get_dummies(test_Y).values\n",
    "print(\"test_Y:\",test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464be98b-d25b-43ad-9e39-5b27e98380cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c782cf4f-9eae-4079-8271-40382e3f437b",
   "metadata": {},
   "source": [
    "# MODEL 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "reasonable-statistics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 2500, 256)         1792000   \n",
      "                                                                 \n",
      " spatial_dropout1d (Spatial  (None, 2500, 256)         0         \n",
      " Dropout1D)                                                      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                82176     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1874371 (7.15 MB)\n",
      "Trainable params: 1874371 (7.15 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabSize, embed_dim,input_length = 2500))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fuzzy-abuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(\"hasoc_a2.h5\", monitor='val_loss', verbose=1, save_best_only=True,\n",
    "save_weights_only=False, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "noble-accused",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14     Negative\n",
      "158    Positive\n",
      "762    Positive\n",
      "740    Positive\n",
      "482    Negative\n",
      "         ...   \n",
      "721    Positive\n",
      "651    Positive\n",
      "782     Neutral\n",
      "113    Positive\n",
      "839    Positive\n",
      "Name: task_2, Length: 134, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(Y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "alone-launch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True False False]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False  True False]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False  True False]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [False  True False]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [False  True False]\n",
      " [False  True False]\n",
      " [ True False False]\n",
      " [False  True False]\n",
      " [ True False False]\n",
      " [ True False False]\n",
      " [False  True False]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [False  True False]\n",
      " [False False  True]\n",
      " [False  True False]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [False  True False]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False  True False]\n",
      " [ True False False]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False  True False]\n",
      " [ True False False]\n",
      " [ True False False]\n",
      " [ True False False]\n",
      " [ True False False]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False  True False]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False  True False]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [False  True False]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [False  True False]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [False  True False]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False  True False]\n",
      " [False  True False]\n",
      " [ True False False]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [False  True False]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [ True False False]\n",
      " [False  True False]\n",
      " [False False  True]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [False  True False]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False  True False]\n",
      " [False False  True]\n",
      " [False False  True]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_test)\n",
    "classes = ['Negative','Neutral','Positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "economic-separate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.6481 - accuracy: 0.4305\n",
      "Epoch 1: val_loss improved from inf to 0.60074, saving model to hasoc_a2.h5\n",
      "24/24 [==============================] - 122s 5s/step - loss: 0.6481 - accuracy: 0.4305 - val_loss: 0.6007 - val_accuracy: 0.5075\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\8888\\Anaconda3\\envs\\pythonProject11\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - ETA: 0s - loss: 0.6096 - accuracy: 0.4450\n",
      "Epoch 2: val_loss improved from 0.60074 to 0.59117, saving model to hasoc_a2.h5\n",
      "24/24 [==============================] - 116s 5s/step - loss: 0.6096 - accuracy: 0.4450 - val_loss: 0.5912 - val_accuracy: 0.5075\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.5928 - accuracy: 0.5245\n",
      "Epoch 3: val_loss did not improve from 0.59117\n",
      "24/24 [==============================] - 117s 5s/step - loss: 0.5928 - accuracy: 0.5245 - val_loss: 0.5955 - val_accuracy: 0.5299\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.5469 - accuracy: 0.5762\n",
      "Epoch 4: val_loss improved from 0.59117 to 0.57304, saving model to hasoc_a2.h5\n",
      "24/24 [==============================] - 118s 5s/step - loss: 0.5469 - accuracy: 0.5762 - val_loss: 0.5730 - val_accuracy: 0.5373\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.4621 - accuracy: 0.6795\n",
      "Epoch 5: val_loss did not improve from 0.57304\n",
      "24/24 [==============================] - 118s 5s/step - loss: 0.4621 - accuracy: 0.6795 - val_loss: 0.5896 - val_accuracy: 0.5299\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.3633 - accuracy: 0.7815\n",
      "Epoch 6: val_loss did not improve from 0.57304\n",
      "24/24 [==============================] - 118s 5s/step - loss: 0.3633 - accuracy: 0.7815 - val_loss: 0.6710 - val_accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.3162 - accuracy: 0.7854\n",
      "Epoch 7: val_loss did not improve from 0.57304\n",
      "24/24 [==============================] - 119s 5s/step - loss: 0.3162 - accuracy: 0.7854 - val_loss: 0.6957 - val_accuracy: 0.5299\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.2521 - accuracy: 0.8477\n",
      "Epoch 8: val_loss did not improve from 0.57304\n",
      "24/24 [==============================] - 119s 5s/step - loss: 0.2521 - accuracy: 0.8477 - val_loss: 0.7797 - val_accuracy: 0.4925\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.2359 - accuracy: 0.8464\n",
      "Epoch 9: val_loss did not improve from 0.57304\n",
      "24/24 [==============================] - 118s 5s/step - loss: 0.2359 - accuracy: 0.8464 - val_loss: 0.8054 - val_accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.2032 - accuracy: 0.8609\n",
      "Epoch 10: val_loss did not improve from 0.57304\n",
      "24/24 [==============================] - 120s 5s/step - loss: 0.2032 - accuracy: 0.8609 - val_loss: 0.8839 - val_accuracy: 0.4851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x207d67a0910>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size = 32, epochs = 10, validation_data=(X_test,Y_test), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41f6cc3e-6497-4bbf-9aa9-7b4b14674ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 552ms/step - loss: 0.5730 - accuracy: 0.5373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5730419158935547, 0.5373134613037109]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('hasoc_a2.h5')\n",
    "model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "frozen-battlefield",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 12s 608ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "guided-damages",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_pred: [[0.18888548 0.18534648 0.625768  ]\n",
      " [0.78411263 0.01164995 0.20423736]\n",
      " [0.20543034 0.07548866 0.71908104]\n",
      " ...\n",
      " [0.3436129  0.07706604 0.579321  ]\n",
      " [0.30682686 0.19628365 0.4968895 ]\n",
      " [0.20232376 0.17370537 0.62397087]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Y_pred:\",Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "handy-times",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 0, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 0, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 0, 0, 2, 0, 0, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0, 2, 0, 0, 2, 2, 0, 2, 0, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 0, 0, 2, 0, 2, 2, 0, 2, 2, 0, 2, 0, 2, 0, 0, 0, 2, 2, 2, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 0, 2, 0, 0, 2, 2, 2, 0, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "[[False False  True]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " ...\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False False  True]]\n"
     ]
    }
   ],
   "source": [
    "pred_class = []\n",
    "for i in Y_pred:\n",
    "    pred_class.append(np.argmax(i))\n",
    "print(pred_class)\n",
    "\n",
    "pred_class_condition = pd.get_dummies(pred_class).values\n",
    "print(pred_class_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "blind-pricing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.39      0.15        31\n",
      "           1       1.00      0.00      0.01       388\n",
      "           2       0.25      0.63      0.35       185\n",
      "\n",
      "   micro avg       0.22      0.22      0.22       604\n",
      "   macro avg       0.45      0.34      0.17       604\n",
      "weighted avg       0.72      0.22      0.12       604\n",
      " samples avg       0.22      0.22      0.22       604\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_Y, pred_class_condition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "tough-houston",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_actual = []\n",
    "for i in pred_class:\n",
    "    if i == 0:\n",
    "        pred_actual.append('Negative')\n",
    "    elif i == 1 :\n",
    "        pred_actual.append('Neutral')\n",
    "    else:\n",
    "        pred_actual.append('Positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dca4e723-467e-437e-8de7-2d77149e8521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gujarati_image_1225.jpg</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gujarati_image_1583.jpg</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gujarati_image_1502.jpg</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gujarati_image_1487.jpg</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gujarati_image_1497.jpg</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       _id     label\n",
       "0  Gujarati_image_1225.jpg  Positive\n",
       "1  Gujarati_image_1583.jpg  Negative\n",
       "2  Gujarati_image_1502.jpg  Positive\n",
       "3  Gujarati_image_1487.jpg  Positive\n",
       "4  Gujarati_image_1497.jpg  Positive"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = test_data[[\"_id\"]]\n",
    "test_data[\"label\"] = pred_actual\n",
    "test_data.to_csv('dl_lstm_a2.csv',index=False)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767c1a06-5063-4b02-b0e5-3aa4e14f484d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dad52e73-8e65-4860-9b25-800c60f7d0a2",
   "metadata": {},
   "source": [
    "# MODEL 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0db69c26-ef93-4613-b725-36a5ecd933f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 2500, 256)         1792000   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2500, 256)         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                82176     \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 64)                256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1874627 (7.15 MB)\n",
      "Trainable params: 1874499 (7.15 MB)\n",
      "Non-trainable params: 128 (512.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Embedding层，增加防止过拟合的Dropout\n",
    "model.add(Embedding(input_dim=vocabSize, output_dim=embed_dim, input_length=2500))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# LSTM层，增加recurrent_dropout 和 output dropout\n",
    "model.add(LSTM(units=lstm_out, dropout=0.3, recurrent_dropout=0.3, return_sequences=False))\n",
    "\n",
    "# Batch Normalization增强泛化\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 全连接层，Softmax输出3分类，建议用categorical_crossentropy\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# 编译\n",
    "optimizer = Adam(learning_rate=0.001)  # 学习率也可调整\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a38b0804-b167-4b4d-a0ca-ee730454e324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(\"hasoc_b2.h5\", monitor='val_loss', verbose=1, save_best_only=True,\n",
    "save_weights_only=False, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a2949a7-774d-4128-8e2b-deff8ca140cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "95/95 [==============================] - ETA: 0s - loss: 1.1750 - accuracy: 0.3815\n",
      "Epoch 1: val_loss improved from inf to 1.03551, saving model to hasoc_b2.h5\n",
      "95/95 [==============================] - 256s 3s/step - loss: 1.1750 - accuracy: 0.3815 - val_loss: 1.0355 - val_accuracy: 0.5075\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\8888\\Anaconda3\\envs\\pythonProject11\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - ETA: 0s - loss: 0.8998 - accuracy: 0.5894\n",
      "Epoch 2: val_loss improved from 1.03551 to 1.01267, saving model to hasoc_b2.h5\n",
      "95/95 [==============================] - 258s 3s/step - loss: 0.8998 - accuracy: 0.5894 - val_loss: 1.0127 - val_accuracy: 0.5149\n",
      "Epoch 3/10\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.7580 - accuracy: 0.6901\n",
      "Epoch 3: val_loss improved from 1.01267 to 1.00446, saving model to hasoc_b2.h5\n",
      "95/95 [==============================] - 259s 3s/step - loss: 0.7580 - accuracy: 0.6901 - val_loss: 1.0045 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.5763 - accuracy: 0.7483\n",
      "Epoch 4: val_loss did not improve from 1.00446\n",
      "95/95 [==============================] - 258s 3s/step - loss: 0.5763 - accuracy: 0.7483 - val_loss: 1.0186 - val_accuracy: 0.5373\n",
      "Epoch 5/10\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.5351 - accuracy: 0.7854\n",
      "Epoch 5: val_loss did not improve from 1.00446\n",
      "95/95 [==============================] - 258s 3s/step - loss: 0.5351 - accuracy: 0.7854 - val_loss: 1.0297 - val_accuracy: 0.4701\n",
      "Epoch 6/10\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.4860 - accuracy: 0.8026\n",
      "Epoch 6: val_loss did not improve from 1.00446\n",
      "95/95 [==============================] - 260s 3s/step - loss: 0.4860 - accuracy: 0.8026 - val_loss: 1.2383 - val_accuracy: 0.4552\n",
      "Epoch 7/10\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.4287 - accuracy: 0.8252\n",
      "Epoch 7: val_loss did not improve from 1.00446\n",
      "95/95 [==============================] - 261s 3s/step - loss: 0.4287 - accuracy: 0.8252 - val_loss: 1.4028 - val_accuracy: 0.4627\n",
      "Epoch 8/10\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.4253 - accuracy: 0.8344\n",
      "Epoch 8: val_loss did not improve from 1.00446\n",
      "95/95 [==============================] - 260s 3s/step - loss: 0.4253 - accuracy: 0.8344 - val_loss: 1.4482 - val_accuracy: 0.4851\n",
      "Epoch 9/10\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.4565 - accuracy: 0.8119\n",
      "Epoch 9: val_loss did not improve from 1.00446\n",
      "95/95 [==============================] - 268s 3s/step - loss: 0.4565 - accuracy: 0.8119 - val_loss: 1.4666 - val_accuracy: 0.4701\n",
      "Epoch 10/10\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.4325 - accuracy: 0.8185\n",
      "Epoch 10: val_loss did not improve from 1.00446\n",
      "95/95 [==============================] - 268s 3s/step - loss: 0.4325 - accuracy: 0.8185 - val_loss: 1.4087 - val_accuracy: 0.5299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e15943ceb0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size = 8, epochs = 10, validation_data = (X_test, Y_test), callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e9a307c-c675-4aa4-8442-861165a5b9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 594ms/step - loss: 1.0045 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0044573545455933, 0.5]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('hasoc_b2.h5')\n",
    "model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a06a1667-1512-4cce-b446-e371b42b8f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 13s 675ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a38a797d-63a9-4942-b86f-af4995be4de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "[[False False  True]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " ...\n",
      " [False False  True]\n",
      " [False False  True]\n",
      " [False False  True]]\n"
     ]
    }
   ],
   "source": [
    "pred_class = []\n",
    "for i in Y_pred:\n",
    "    pred_class.append(np.argmax(i))\n",
    "print(pred_class)\n",
    "\n",
    "pred_class_condition = pd.get_dummies(pred_class).values\n",
    "print(pred_class_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "457c23db-7d84-47e1-88e9-e9804d3c7277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.13      0.10        31\n",
      "           1       1.00      0.00      0.01       388\n",
      "           2       0.29      0.88      0.44       185\n",
      "\n",
      "   micro avg       0.28      0.28      0.28       604\n",
      "   macro avg       0.46      0.34      0.18       604\n",
      "weighted avg       0.74      0.28      0.14       604\n",
      " samples avg       0.28      0.28      0.28       604\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_Y, pred_class_condition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5899b134-2783-4819-b7cb-58ccc0c98008",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_actual = []\n",
    "for i in pred_class:\n",
    "    if i == 0:\n",
    "        pred_actual.append('Negative')\n",
    "    elif i == 1 :\n",
    "        pred_actual.append('Neutral')\n",
    "    else:\n",
    "        pred_actual.append('Positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c6f3fc1-1aa4-4472-b7ce-04cd418db380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gujarati_image_1225.jpg</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gujarati_image_1583.jpg</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gujarati_image_1502.jpg</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gujarati_image_1487.jpg</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gujarati_image_1497.jpg</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       _id     label\n",
       "0  Gujarati_image_1225.jpg  Positive\n",
       "1  Gujarati_image_1583.jpg  Negative\n",
       "2  Gujarati_image_1502.jpg  Positive\n",
       "3  Gujarati_image_1487.jpg  Positive\n",
       "4  Gujarati_image_1497.jpg  Positive"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = test_data[[\"_id\"]]\n",
    "test_data[\"label\"] = pred_actual\n",
    "test_data.to_csv('dl_lstm_b2.csv',index=False)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfb41ef-e5ef-4962-89a9-b45985457b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfef33f7-08c4-4154-9bcf-6575987bb744",
   "metadata": {},
   "source": [
    "# MODEL 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a29c2d09-b109-47a4-a1df-39d09a3e03e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(\n",
    "    \"hasoc_c2.h5\",\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False, \n",
    "    mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b2f2b6c-7a3c-451e-a2ed-3f365a0ee348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "95/95 [==============================] - ETA: 0s - loss: 1.0998 - accuracy: 0.3510\n",
      "Epoch 1: val_loss improved from inf to 1.07681, saving model to hasoc_c2.h5\n",
      "95/95 [==============================] - 166s 2s/step - loss: 1.0998 - accuracy: 0.3510 - val_loss: 1.0768 - val_accuracy: 0.4254\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\8888\\Anaconda3\\envs\\pythonProject11\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - ETA: 0s - loss: 1.0288 - accuracy: 0.5007\n",
      "Epoch 2: val_loss improved from 1.07681 to 1.05034, saving model to hasoc_c2.h5\n",
      "95/95 [==============================] - 185s 2s/step - loss: 1.0288 - accuracy: 0.5007 - val_loss: 1.0503 - val_accuracy: 0.4179\n",
      "Epoch 3/10\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.7809 - accuracy: 0.6384\n",
      "Epoch 3: val_loss did not improve from 1.05034\n",
      "95/95 [==============================] - 187s 2s/step - loss: 0.7809 - accuracy: 0.6384 - val_loss: 1.1502 - val_accuracy: 0.4478\n",
      "Epoch 4/10\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.5363 - accuracy: 0.7550\n",
      "Epoch 4: val_loss did not improve from 1.05034\n",
      "95/95 [==============================] - 185s 2s/step - loss: 0.5363 - accuracy: 0.7550 - val_loss: 1.1926 - val_accuracy: 0.4627\n",
      "Epoch 5/10\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.3672 - accuracy: 0.8278\n",
      "Epoch 5: val_loss did not improve from 1.05034\n",
      "95/95 [==============================] - 188s 2s/step - loss: 0.3672 - accuracy: 0.8278 - val_loss: 1.4436 - val_accuracy: 0.4179\n",
      "Epoch 6/10\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.3155 - accuracy: 0.8464\n",
      "Epoch 6: val_loss did not improve from 1.05034\n",
      "95/95 [==============================] - 187s 2s/step - loss: 0.3155 - accuracy: 0.8464 - val_loss: 1.4136 - val_accuracy: 0.4925\n",
      "Epoch 7/10\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.3077 - accuracy: 0.8477\n",
      "Epoch 7: val_loss did not improve from 1.05034\n",
      "95/95 [==============================] - 187s 2s/step - loss: 0.3077 - accuracy: 0.8477 - val_loss: 1.4765 - val_accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.3044 - accuracy: 0.8411\n",
      "Epoch 8: val_loss did not improve from 1.05034\n",
      "95/95 [==============================] - 185s 2s/step - loss: 0.3044 - accuracy: 0.8411 - val_loss: 1.4388 - val_accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.2803 - accuracy: 0.8623\n",
      "Epoch 9: val_loss did not improve from 1.05034\n",
      "95/95 [==============================] - 185s 2s/step - loss: 0.2803 - accuracy: 0.8623 - val_loss: 1.5943 - val_accuracy: 0.4403\n",
      "Epoch 10/10\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.2668 - accuracy: 0.8424\n",
      "Epoch 10: val_loss did not improve from 1.05034\n",
      "95/95 [==============================] - 186s 2s/step - loss: 0.2668 - accuracy: 0.8424 - val_loss: 1.6706 - val_accuracy: 0.4925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2350b252460>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabSize, embed_dim, input_length=2500))\n",
    "model.add(LSTM(lstm_out, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "# 假设Y_train已独热编码\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.array([0, 1, 2]), y=np.argmax(Y_train, axis=1))\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=10, batch_size=8, class_weight=class_weight_dict, validation_data=(X_test,Y_test), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50e2c3b5-7090-4159-8e38-1d8264db6a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 522ms/step - loss: 1.0503 - accuracy: 0.4179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0503442287445068, 0.41791045665740967]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('hasoc_c2.h5')\n",
    "model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afe7dbcc-992a-4b64-bb2d-939e14b80647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 11s 577ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d73c5c03-0665-44bd-bdba-da032579465e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 0, 1, 1, 1, 0, 1, 0, 2, 0, 1, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 0, 2, 1, 0, 2, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 2, 1, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 1, 2, 0, 1, 1, 2, 0, 0, 1, 2, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 2, 1, 1, 0, 0, 1, 0, 2, 0, 2, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 2, 0, 1, 1, 0, 2, 2, 0, 1, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 2, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 2, 0, 0, 0, 1, 2, 0, 0, 0, 2, 0, 1, 0, 1, 0, 2, 1, 0, 1, 1, 1, 2, 1, 2, 0, 0, 2, 1, 0, 2, 2, 2, 2, 1, 0, 2, 2, 2, 2, 0, 2, 0, 1, 2, 2, 1, 1, 1, 0, 1, 2, 1, 1, 1, 2, 1, 1, 2, 0, 1, 2, 2, 1, 0, 0, 1, 1, 1, 1, 2, 2, 1, 1, 0, 1, 2, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 0, 2, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 1, 1, 1, 1, 2, 0, 1, 0, 2, 2, 2, 1, 0, 1, 1, 1, 2, 1, 2, 0, 1, 0, 2, 0, 0, 1, 1, 2, 1, 1, 0, 1, 2, 1, 1, 0, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 0, 0, 1, 0, 2, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 0, 2, 0, 0, 2, 2, 2, 0, 0, 0, 1, 2, 0, 0, 1, 1, 0, 1, 1, 2, 0, 2, 0, 1, 2, 1, 2, 1, 2, 0, 0, 1, 1, 1, 2, 1, 2, 0, 1, 2, 0, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 0, 1, 2, 0, 0, 2, 0, 0, 0, 1, 2, 0, 1, 1, 1, 0, 0, 2, 0, 2, 1, 1, 1, 1, 1, 0, 1, 2, 1, 0, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 0, 1, 2, 1, 0, 2, 1, 1, 1, 1, 2, 1, 0, 1, 2, 0, 2, 1, 2, 0, 1, 1, 2, 2, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 2, 1, 1, 0, 1, 2, 1, 2, 1, 0, 1, 2, 2, 0, 0, 1, 1, 1, 1, 1, 2, 1, 2, 0, 1, 2, 1, 2, 0, 1, 2, 1, 1, 0, 1, 0, 2, 2, 1, 1, 2, 1, 0, 0, 0, 2, 2, 1, 0, 1, 1, 1, 1, 2, 2, 1, 1, 2, 0, 1, 1, 2, 0, 2, 2, 0, 1, 0, 2, 2, 0, 1, 1, 2, 1, 1, 2]\n",
      "[[False False  True]\n",
      " [ True False False]\n",
      " [False  True False]\n",
      " ...\n",
      " [False  True False]\n",
      " [False  True False]\n",
      " [False False  True]]\n"
     ]
    }
   ],
   "source": [
    "pred_class = []\n",
    "for i in Y_pred:\n",
    "    pred_class.append(np.argmax(i))\n",
    "print(pred_class)\n",
    "\n",
    "pred_class_condition = pd.get_dummies(pred_class).values\n",
    "print(pred_class_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04a7d166-8968-4fc1-af80-8fc72876a74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.58      0.15        31\n",
      "           1       0.72      0.46      0.56       388\n",
      "           2       0.15      0.12      0.13       185\n",
      "\n",
      "   micro avg       0.36      0.36      0.36       604\n",
      "   macro avg       0.32      0.39      0.28       604\n",
      "weighted avg       0.51      0.36      0.41       604\n",
      " samples avg       0.36      0.36      0.36       604\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_Y, pred_class_condition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3c6b3f4-f810-497e-933b-91fd9d299c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_actual = []\n",
    "for i in pred_class:\n",
    "    if i == 0:\n",
    "        pred_actual.append('Negative')\n",
    "    elif i == 1 :\n",
    "        pred_actual.append('Neutral')\n",
    "    else:\n",
    "        pred_actual.append('Positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3293985d-9a83-4d5f-9645-5daf868bded7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gujarati_image_1225.jpg</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gujarati_image_1583.jpg</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gujarati_image_1502.jpg</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gujarati_image_1487.jpg</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gujarati_image_1497.jpg</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       _id     label\n",
       "0  Gujarati_image_1225.jpg  Positive\n",
       "1  Gujarati_image_1583.jpg  Negative\n",
       "2  Gujarati_image_1502.jpg   Neutral\n",
       "3  Gujarati_image_1487.jpg   Neutral\n",
       "4  Gujarati_image_1497.jpg   Neutral"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = test_data[[\"_id\"]]\n",
    "test_data[\"label\"] = pred_actual\n",
    "test_data.to_csv('dl_lstm_c2.csv',index=False)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3615f705-a987-4dc1-b886-a9fd4ffde538",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
